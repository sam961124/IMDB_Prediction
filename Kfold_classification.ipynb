{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def read_data(adjusted):\n",
    "#     if adjusted:\n",
    "#         data_file = pd.read_csv('train_adjusted.csv', encoding='cp950')\n",
    "#         return data_file\n",
    "#     else:\n",
    "#         data_file = pd.read_csv('MOVIES_WITHOUT_ADJUSTED.csv', encoding='cp950')\n",
    "#         return data_file\n",
    "def preprocessing(data_file):\n",
    "    country = []\n",
    "    genre = []\n",
    "    date = []\n",
    "    data_length = len(data_file)\n",
    "    for i in range(data_length):\n",
    "        t_country = str(data_file['COUNTRY'][i]).split(',')\n",
    "        t_genre = str(data_file['IMDB_GENRE'][i]).split(',')\n",
    "        t_date = str(data_file['DATE_TW'][i]).split('/')\n",
    "        t_date = [ int(d) for d in t_date]\n",
    "        country.append(t_country)\n",
    "        genre.append(t_genre)\n",
    "        date.append(t_date)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    country = mlb.fit_transform(country)\n",
    "    genre = mlb.fit_transform(genre)\n",
    "    date = np.array(date)\n",
    "    runtime = np.array(data_file['IMDB_RUNTIME']).reshape(data_length, 1)\n",
    "    dir_detail = np.array(data_file[['DIRECTOR_WINS', 'DIRECTOR_NOMINATIONS', \n",
    "                                     'DIRECTOR_RATINGS']])\n",
    "    star_detail = np.array(data_file[['STAR_1_WINS', 'STAR_1_NOMINATIONS', \n",
    "                                      'STAR_1_RATINGS', 'STAR_2_WINS', \n",
    "                                      'STAR_2_NOMINATIONS', 'STAR_2_RATINGS', \n",
    "                                      'STAR_3_WINS', 'STAR_3_NOMINATIONS', \n",
    "                                      'STAR_3_RATINGS']])\n",
    "    yahoo = np.array(data_file[['YAHOO_EVALUATION', 'YAHOO_VOTER']])\n",
    "    PTT = np.array(data_file[['PTT_ARTICLE', 'PTT_PUSH', 'PTT_ARROW', \n",
    "                              'PTT_PULL', 'PTT_REPLY']])\n",
    "    youtube = np.array(data_file[['YOUTUBE_VIEW', 'YOUTUBE_LIKE', 'YOUTUBE_DISLIKE']])\n",
    "    x_train = np.concatenate((country, genre, runtime, dir_detail, star_detail, \n",
    "                          yahoo, PTT, youtube), axis=-1)\n",
    "    rating = np.array(data_file['IMDB_RATING']).reshape(data_length, 1)\n",
    "    return x_train, rating\n",
    "def set_class(rating, g_1, g_2):\n",
    "    y_train = []\n",
    "    for r in rating:\n",
    "        temp = 0\n",
    "        if r >= g_1:\n",
    "            temp = 0\n",
    "        elif r >= g_2:\n",
    "            temp = 1\n",
    "        else:\n",
    "            temp = 2\n",
    "        y_train.append(temp)\n",
    "    y_train = np.array(y_train)\n",
    "    return y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read training data\n",
    "x_train, rating = np.load('x_train.npy'), np.load('y_train.npy')\n",
    "n_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_1, g_2 = 7.0, 6.0\n",
    "y_train = set_class(rating, g_1, g_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training normalization\n",
    "mean = np.mean(x_train, axis=0)\n",
    "sigma = np.std(x_train, axis=0)\n",
    "x_train = (x_train-mean)/(sigma + 1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read testing data\n",
    "x_test, test_rating = np.load('x_test.npy'), np.load('y_test.npy')\n",
    "y_test = set_class(test_rating, g_1, g_2)\n",
    "\n",
    "# testing normalization\n",
    "x_test = (x_test-mean)/(sigma + 1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(dnn):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    for units in dnn:\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 2s - loss: 2.1127 - acc: 0.3270 - val_loss: 1.1422 - val_acc: 0.3333\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.9419 - acc: 0.3522 - val_loss: 1.1151 - val_acc: 0.3889\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.6561 - acc: 0.3899 - val_loss: 1.0978 - val_acc: 0.3889\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 1.5383 - acc: 0.3648 - val_loss: 1.0871 - val_acc: 0.3889\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 1.5761 - acc: 0.3145 - val_loss: 1.0776 - val_acc: 0.3333\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 1.7599 - acc: 0.3082 - val_loss: 1.0698 - val_acc: 0.2778\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 1.5036 - acc: 0.3522 - val_loss: 1.0605 - val_acc: 0.2222\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 1.4752 - acc: 0.3522 - val_loss: 1.0534 - val_acc: 0.2222\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s - loss: 1.4407 - acc: 0.3899 - val_loss: 1.0453 - val_acc: 0.2222\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s - loss: 1.4432 - acc: 0.3711 - val_loss: 1.0455 - val_acc: 0.2778\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s - loss: 1.5325 - acc: 0.3648 - val_loss: 1.0459 - val_acc: 0.3889\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s - loss: 1.3084 - acc: 0.4528 - val_loss: 1.0458 - val_acc: 0.3333\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s - loss: 1.4010 - acc: 0.3459 - val_loss: 1.0491 - val_acc: 0.3333\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 0s - loss: 1.7467 - acc: 0.3082 - val_loss: 1.2313 - val_acc: 0.3333\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.6938 - acc: 0.3585 - val_loss: 1.2237 - val_acc: 0.3333\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.6375 - acc: 0.3459 - val_loss: 1.2125 - val_acc: 0.3333\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 1.5873 - acc: 0.3145 - val_loss: 1.2040 - val_acc: 0.3889\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 1.6340 - acc: 0.3333 - val_loss: 1.1906 - val_acc: 0.3889\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 1.4894 - acc: 0.3774 - val_loss: 1.1769 - val_acc: 0.3333\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 1.4288 - acc: 0.3711 - val_loss: 1.1645 - val_acc: 0.3333\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 1.3461 - acc: 0.3585 - val_loss: 1.1552 - val_acc: 0.3333\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s - loss: 1.3030 - acc: 0.3962 - val_loss: 1.1460 - val_acc: 0.3333\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s - loss: 1.3552 - acc: 0.3774 - val_loss: 1.1390 - val_acc: 0.3333\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s - loss: 1.3776 - acc: 0.4025 - val_loss: 1.1276 - val_acc: 0.3333\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s - loss: 1.4065 - acc: 0.3019 - val_loss: 1.1147 - val_acc: 0.3889\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s - loss: 1.3959 - acc: 0.3899 - val_loss: 1.1057 - val_acc: 0.3889\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s - loss: 1.1913 - acc: 0.4717 - val_loss: 1.0956 - val_acc: 0.5000\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 0s - loss: 1.3548 - acc: 0.3459 - val_loss: 1.0842 - val_acc: 0.4444\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 0s - loss: 1.1856 - acc: 0.4340 - val_loss: 1.0736 - val_acc: 0.5000\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 0s - loss: 1.3350 - acc: 0.3711 - val_loss: 1.0641 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 0s - loss: 1.1952 - acc: 0.4214 - val_loss: 1.0548 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 0s - loss: 1.3036 - acc: 0.3962 - val_loss: 1.0466 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 0s - loss: 1.2689 - acc: 0.3962 - val_loss: 1.0388 - val_acc: 0.4444\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 0s - loss: 1.2512 - acc: 0.4465 - val_loss: 1.0327 - val_acc: 0.4444\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 0s - loss: 1.0855 - acc: 0.4528 - val_loss: 1.0307 - val_acc: 0.4444\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 0s - loss: 1.0606 - acc: 0.5157 - val_loss: 1.0269 - val_acc: 0.3889\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 0s - loss: 1.1066 - acc: 0.5220 - val_loss: 1.0217 - val_acc: 0.3333\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 0s - loss: 1.1169 - acc: 0.4969 - val_loss: 1.0166 - val_acc: 0.3333\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 0s - loss: 1.0497 - acc: 0.5283 - val_loss: 1.0138 - val_acc: 0.3889\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 0s - loss: 1.0760 - acc: 0.4403 - val_loss: 1.0085 - val_acc: 0.4444\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 0s - loss: 1.2964 - acc: 0.3522 - val_loss: 1.0036 - val_acc: 0.4444\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 0s - loss: 1.1734 - acc: 0.4340 - val_loss: 1.0018 - val_acc: 0.4444\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 0s - loss: 1.1398 - acc: 0.4403 - val_loss: 1.0017 - val_acc: 0.4444\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 0s - loss: 1.2359 - acc: 0.4780 - val_loss: 1.0014 - val_acc: 0.5000\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 0s - loss: 1.0815 - acc: 0.4780 - val_loss: 0.9989 - val_acc: 0.4444\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 0s - loss: 1.1413 - acc: 0.4465 - val_loss: 0.9961 - val_acc: 0.5000\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 0s - loss: 1.0762 - acc: 0.4843 - val_loss: 0.9913 - val_acc: 0.5000\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 0s - loss: 1.0397 - acc: 0.5346 - val_loss: 0.9891 - val_acc: 0.5000\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 0s - loss: 1.1110 - acc: 0.5094 - val_loss: 0.9876 - val_acc: 0.4444\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 0s - loss: 1.0416 - acc: 0.5409 - val_loss: 0.9821 - val_acc: 0.3889\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 0s - loss: 1.0107 - acc: 0.4843 - val_loss: 0.9773 - val_acc: 0.3889\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 0s - loss: 1.0130 - acc: 0.5157 - val_loss: 0.9750 - val_acc: 0.4444\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 0s - loss: 1.0276 - acc: 0.4780 - val_loss: 0.9731 - val_acc: 0.3889\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 0s - loss: 1.0754 - acc: 0.4465 - val_loss: 0.9725 - val_acc: 0.3889\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 0s - loss: 1.0486 - acc: 0.4654 - val_loss: 0.9753 - val_acc: 0.3889\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 0s - loss: 1.0236 - acc: 0.5220 - val_loss: 0.9729 - val_acc: 0.3333\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 0s - loss: 0.9951 - acc: 0.5409 - val_loss: 0.9679 - val_acc: 0.3333\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 0s - loss: 0.9454 - acc: 0.5849 - val_loss: 0.9641 - val_acc: 0.3333\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 0s - loss: 0.9231 - acc: 0.5849 - val_loss: 0.9671 - val_acc: 0.3889\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 0s - loss: 0.9286 - acc: 0.5346 - val_loss: 0.9698 - val_acc: 0.4444\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 0s - loss: 0.9124 - acc: 0.6101 - val_loss: 0.9711 - val_acc: 0.4444\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - 0s - loss: 0.9654 - acc: 0.5283 - val_loss: 0.9695 - val_acc: 0.4444\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s - loss: 1.9107 - acc: 0.2453 - val_loss: 1.0294 - val_acc: 0.2778\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.5879 - acc: 0.3145 - val_loss: 1.0394 - val_acc: 0.2778\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s - loss: 1.6288 - acc: 0.3082 - val_loss: 1.0437 - val_acc: 0.2778\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 1.6599 - acc: 0.3145 - val_loss: 1.0460 - val_acc: 0.2222\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 1.5047 - acc: 0.3585 - val_loss: 1.0455 - val_acc: 0.2778\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s - loss: 1.6639 - acc: 0.3585 - val_loss: 1.0375 - val_acc: 0.4444\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.8452 - acc: 0.2956 - val_loss: 1.0430 - val_acc: 0.5000\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.6138 - acc: 0.3648 - val_loss: 1.0450 - val_acc: 0.5000\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 1.6421 - acc: 0.3396 - val_loss: 1.0466 - val_acc: 0.4444\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 1.6803 - acc: 0.3019 - val_loss: 1.0455 - val_acc: 0.4444\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s - loss: 1.6959 - acc: 0.3522 - val_loss: 1.0698 - val_acc: 0.2778\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.7810 - acc: 0.3208 - val_loss: 1.0471 - val_acc: 0.3333\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.7824 - acc: 0.3208 - val_loss: 1.0291 - val_acc: 0.5556\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 1.6149 - acc: 0.4088 - val_loss: 1.0176 - val_acc: 0.5556\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 1.7447 - acc: 0.3082 - val_loss: 1.0076 - val_acc: 0.5556\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 1.4839 - acc: 0.3774 - val_loss: 0.9987 - val_acc: 0.6111\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 1.3883 - acc: 0.4151 - val_loss: 0.9933 - val_acc: 0.6111\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 1.5139 - acc: 0.4088 - val_loss: 0.9899 - val_acc: 0.5556\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s - loss: 1.3810 - acc: 0.4214 - val_loss: 0.9875 - val_acc: 0.6111\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s - loss: 1.3838 - acc: 0.3899 - val_loss: 0.9854 - val_acc: 0.6111\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s - loss: 1.3215 - acc: 0.4088 - val_loss: 0.9868 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s - loss: 1.3443 - acc: 0.4403 - val_loss: 0.9865 - val_acc: 0.5000\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s - loss: 1.3364 - acc: 0.4528 - val_loss: 0.9884 - val_acc: 0.4444\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s - loss: 1.2041 - acc: 0.4654 - val_loss: 0.9883 - val_acc: 0.4444\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s - loss: 1.9291 - acc: 0.3145 - val_loss: 1.2223 - val_acc: 0.2222\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.6345 - acc: 0.3648 - val_loss: 1.1784 - val_acc: 0.2222\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.7742 - acc: 0.3585 - val_loss: 1.1487 - val_acc: 0.2222\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 1.5883 - acc: 0.3648 - val_loss: 1.1195 - val_acc: 0.2778\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 1.5596 - acc: 0.3899 - val_loss: 1.0894 - val_acc: 0.3889\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 1.6525 - acc: 0.3774 - val_loss: 1.0646 - val_acc: 0.5000\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 1.6788 - acc: 0.3585 - val_loss: 1.0417 - val_acc: 0.5000\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 1.3535 - acc: 0.3396 - val_loss: 1.0220 - val_acc: 0.5556\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s - loss: 1.5622 - acc: 0.3774 - val_loss: 1.0078 - val_acc: 0.6111\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s - loss: 1.5364 - acc: 0.3774 - val_loss: 0.9970 - val_acc: 0.6111\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s - loss: 1.3285 - acc: 0.4088 - val_loss: 0.9871 - val_acc: 0.6111\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s - loss: 1.1501 - acc: 0.4906 - val_loss: 0.9789 - val_acc: 0.6111\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s - loss: 1.4301 - acc: 0.3899 - val_loss: 0.9734 - val_acc: 0.6111\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s - loss: 1.4063 - acc: 0.3585 - val_loss: 0.9707 - val_acc: 0.6667\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 0s - loss: 1.3093 - acc: 0.4277 - val_loss: 0.9712 - val_acc: 0.6667\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 0s - loss: 1.3794 - acc: 0.3648 - val_loss: 0.9727 - val_acc: 0.6667\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 0s - loss: 1.0946 - acc: 0.4654 - val_loss: 0.9706 - val_acc: 0.6667\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 0s - loss: 1.3568 - acc: 0.4214 - val_loss: 0.9683 - val_acc: 0.6667\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 0s - loss: 1.2135 - acc: 0.4340 - val_loss: 0.9623 - val_acc: 0.6667\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 0s - loss: 1.2330 - acc: 0.4780 - val_loss: 0.9551 - val_acc: 0.7222\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 0s - loss: 1.2089 - acc: 0.4843 - val_loss: 0.9494 - val_acc: 0.7222\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 0s - loss: 1.2515 - acc: 0.4528 - val_loss: 0.9420 - val_acc: 0.7222\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 0s - loss: 1.2097 - acc: 0.4843 - val_loss: 0.9360 - val_acc: 0.7222\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 0s - loss: 1.1824 - acc: 0.4591 - val_loss: 0.9345 - val_acc: 0.7222\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 0s - loss: 1.2017 - acc: 0.4654 - val_loss: 0.9396 - val_acc: 0.6667\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 0s - loss: 1.1940 - acc: 0.5094 - val_loss: 0.9421 - val_acc: 0.6667\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 0s - loss: 1.1296 - acc: 0.4906 - val_loss: 0.9383 - val_acc: 0.6667\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 0s - loss: 1.2790 - acc: 0.4277 - val_loss: 0.9372 - val_acc: 0.6111\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 1s - loss: 1.6271 - acc: 0.3082 - val_loss: 1.1616 - val_acc: 0.2222\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.5591 - acc: 0.3459 - val_loss: 1.1399 - val_acc: 0.2778\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.5494 - acc: 0.3774 - val_loss: 1.1185 - val_acc: 0.3889\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 1.5671 - acc: 0.3585 - val_loss: 1.1026 - val_acc: 0.4444\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 1.4881 - acc: 0.3648 - val_loss: 1.0845 - val_acc: 0.4444\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 1.4080 - acc: 0.4214 - val_loss: 1.0711 - val_acc: 0.4444\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 1.2720 - acc: 0.4214 - val_loss: 1.0619 - val_acc: 0.3889\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 1.3529 - acc: 0.3648 - val_loss: 1.0552 - val_acc: 0.4444\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s - loss: 1.2129 - acc: 0.3962 - val_loss: 1.0526 - val_acc: 0.5000\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s - loss: 1.2681 - acc: 0.3836 - val_loss: 1.0502 - val_acc: 0.5000\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s - loss: 1.3064 - acc: 0.3836 - val_loss: 1.0493 - val_acc: 0.5556\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s - loss: 1.1798 - acc: 0.4465 - val_loss: 1.0460 - val_acc: 0.5556\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s - loss: 1.2673 - acc: 0.4465 - val_loss: 1.0441 - val_acc: 0.5556\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s - loss: 1.1403 - acc: 0.4654 - val_loss: 1.0390 - val_acc: 0.5556\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s - loss: 1.1094 - acc: 0.4717 - val_loss: 1.0353 - val_acc: 0.5556\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 0s - loss: 1.2289 - acc: 0.4717 - val_loss: 1.0339 - val_acc: 0.5556\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 0s - loss: 1.2142 - acc: 0.4277 - val_loss: 1.0322 - val_acc: 0.5000\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 0s - loss: 1.0187 - acc: 0.5094 - val_loss: 1.0275 - val_acc: 0.5000\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 0s - loss: 1.1193 - acc: 0.4528 - val_loss: 1.0221 - val_acc: 0.5000\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 0s - loss: 1.1428 - acc: 0.4465 - val_loss: 1.0186 - val_acc: 0.5000\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 0s - loss: 1.1472 - acc: 0.4277 - val_loss: 1.0155 - val_acc: 0.5000\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 0s - loss: 1.1582 - acc: 0.4654 - val_loss: 1.0131 - val_acc: 0.5000\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 0s - loss: 1.0273 - acc: 0.4843 - val_loss: 1.0099 - val_acc: 0.5000\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 0s - loss: 1.0477 - acc: 0.5157 - val_loss: 1.0088 - val_acc: 0.6111\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 0s - loss: 1.0913 - acc: 0.4906 - val_loss: 1.0120 - val_acc: 0.6111\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 0s - loss: 1.0072 - acc: 0.5409 - val_loss: 1.0166 - val_acc: 0.6111\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 0s - loss: 1.0779 - acc: 0.4906 - val_loss: 1.0167 - val_acc: 0.6111\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 0s - loss: 1.1069 - acc: 0.4906 - val_loss: 1.0137 - val_acc: 0.6111\n",
      "Train on 160 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 1s - loss: 1.7429 - acc: 0.3125 - val_loss: 1.1045 - val_acc: 0.3529\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 0s - loss: 1.6721 - acc: 0.3500 - val_loss: 1.0885 - val_acc: 0.3529\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 0s - loss: 1.6749 - acc: 0.3563 - val_loss: 1.0762 - val_acc: 0.4118\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 0s - loss: 1.5669 - acc: 0.3438 - val_loss: 1.0674 - val_acc: 0.4118\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 0s - loss: 1.7088 - acc: 0.2938 - val_loss: 1.0723 - val_acc: 0.4118\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 0s - loss: 1.3617 - acc: 0.3813 - val_loss: 1.0766 - val_acc: 0.4118\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 0s - loss: 1.4046 - acc: 0.3625 - val_loss: 1.0801 - val_acc: 0.4118\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 0s - loss: 1.3174 - acc: 0.4438 - val_loss: 1.0842 - val_acc: 0.4118\n",
      "Train on 160 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 1s - loss: 1.6206 - acc: 0.2938 - val_loss: 1.1800 - val_acc: 0.2353\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 0s - loss: 1.5686 - acc: 0.3125 - val_loss: 1.1662 - val_acc: 0.2353\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 0s - loss: 1.3725 - acc: 0.4000 - val_loss: 1.1506 - val_acc: 0.2353\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 0s - loss: 1.4694 - acc: 0.3250 - val_loss: 1.1371 - val_acc: 0.2353\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 0s - loss: 1.4057 - acc: 0.3813 - val_loss: 1.1231 - val_acc: 0.2941\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 0s - loss: 1.4637 - acc: 0.3625 - val_loss: 1.1101 - val_acc: 0.3529\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 0s - loss: 1.3754 - acc: 0.3875 - val_loss: 1.0973 - val_acc: 0.3529\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 0s - loss: 1.2218 - acc: 0.4625 - val_loss: 1.0849 - val_acc: 0.3529\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 0s - loss: 1.2932 - acc: 0.4250 - val_loss: 1.0716 - val_acc: 0.3529\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 0s - loss: 1.2094 - acc: 0.3937 - val_loss: 1.0615 - val_acc: 0.4118\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 0s - loss: 1.4836 - acc: 0.3250 - val_loss: 1.0509 - val_acc: 0.4118\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 0s - loss: 1.2180 - acc: 0.4125 - val_loss: 1.0411 - val_acc: 0.5294\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 0s - loss: 1.1487 - acc: 0.4562 - val_loss: 1.0316 - val_acc: 0.5294\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 0s - loss: 1.0696 - acc: 0.5187 - val_loss: 1.0236 - val_acc: 0.5294\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 0s - loss: 1.2154 - acc: 0.3625 - val_loss: 1.0172 - val_acc: 0.5294\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 0s - loss: 1.0196 - acc: 0.5563 - val_loss: 1.0108 - val_acc: 0.5294\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 0s - loss: 1.0857 - acc: 0.4688 - val_loss: 1.0051 - val_acc: 0.5294\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 0s - loss: 1.1356 - acc: 0.4562 - val_loss: 0.9985 - val_acc: 0.5294\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 0s - loss: 1.0896 - acc: 0.5312 - val_loss: 0.9914 - val_acc: 0.5882\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 0s - loss: 1.0509 - acc: 0.5375 - val_loss: 0.9838 - val_acc: 0.5882\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 0s - loss: 1.1205 - acc: 0.4875 - val_loss: 0.9754 - val_acc: 0.5882\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 0s - loss: 1.0785 - acc: 0.4937 - val_loss: 0.9676 - val_acc: 0.5882\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 0s - loss: 1.1043 - acc: 0.5125 - val_loss: 0.9584 - val_acc: 0.6471\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 0s - loss: 1.1606 - acc: 0.4562 - val_loss: 0.9501 - val_acc: 0.5882\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 0s - loss: 1.1134 - acc: 0.4312 - val_loss: 0.9478 - val_acc: 0.5882\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 0s - loss: 1.1041 - acc: 0.5125 - val_loss: 0.9451 - val_acc: 0.5882\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 0s - loss: 1.1221 - acc: 0.4813 - val_loss: 0.9410 - val_acc: 0.5882\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 0s - loss: 1.0813 - acc: 0.5187 - val_loss: 0.9349 - val_acc: 0.5882\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 0s - loss: 1.1051 - acc: 0.4500 - val_loss: 0.9288 - val_acc: 0.5882\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 0s - loss: 0.9944 - acc: 0.5187 - val_loss: 0.9238 - val_acc: 0.5882\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 0s - loss: 0.9308 - acc: 0.5687 - val_loss: 0.9186 - val_acc: 0.5882\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 0s - loss: 1.0946 - acc: 0.4250 - val_loss: 0.9127 - val_acc: 0.5882\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 0s - loss: 1.0267 - acc: 0.5312 - val_loss: 0.9068 - val_acc: 0.5882\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 0s - loss: 0.9896 - acc: 0.5312 - val_loss: 0.9015 - val_acc: 0.5882\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 0s - loss: 0.9645 - acc: 0.5250 - val_loss: 0.8950 - val_acc: 0.5882\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 0s - loss: 1.0254 - acc: 0.4875 - val_loss: 0.8857 - val_acc: 0.6471\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 0s - loss: 0.9044 - acc: 0.5875 - val_loss: 0.8788 - val_acc: 0.6471\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 0s - loss: 0.9820 - acc: 0.5563 - val_loss: 0.8690 - val_acc: 0.7059\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 0s - loss: 0.9649 - acc: 0.5375 - val_loss: 0.8609 - val_acc: 0.7059\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 0s - loss: 1.0374 - acc: 0.5125 - val_loss: 0.8558 - val_acc: 0.7059\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 0s - loss: 0.9344 - acc: 0.5500 - val_loss: 0.8479 - val_acc: 0.7059\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 0s - loss: 0.9605 - acc: 0.5250 - val_loss: 0.8414 - val_acc: 0.7059\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 0s - loss: 0.8976 - acc: 0.5500 - val_loss: 0.8346 - val_acc: 0.7059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "160/160 [==============================] - 0s - loss: 0.9604 - acc: 0.5812 - val_loss: 0.8287 - val_acc: 0.7059\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 0s - loss: 0.8636 - acc: 0.6125 - val_loss: 0.8231 - val_acc: 0.7059\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 0s - loss: 0.8771 - acc: 0.6063 - val_loss: 0.8163 - val_acc: 0.7059\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 0s - loss: 0.8297 - acc: 0.6250 - val_loss: 0.8112 - val_acc: 0.7059\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 0s - loss: 0.9138 - acc: 0.5563 - val_loss: 0.8093 - val_acc: 0.6471\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 0s - loss: 0.8750 - acc: 0.5687 - val_loss: 0.8057 - val_acc: 0.7059\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 0s - loss: 0.9168 - acc: 0.5375 - val_loss: 0.8058 - val_acc: 0.6471\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 0s - loss: 0.7974 - acc: 0.6188 - val_loss: 0.8019 - val_acc: 0.6471\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 0s - loss: 0.8401 - acc: 0.6000 - val_loss: 0.7977 - val_acc: 0.6471\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 0s - loss: 0.9552 - acc: 0.5000 - val_loss: 0.7918 - val_acc: 0.6471\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 0s - loss: 0.9043 - acc: 0.5750 - val_loss: 0.7861 - val_acc: 0.5882\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 0s - loss: 0.8857 - acc: 0.5750 - val_loss: 0.7836 - val_acc: 0.5882\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 0s - loss: 0.8750 - acc: 0.6375 - val_loss: 0.7804 - val_acc: 0.5882\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 0s - loss: 0.8321 - acc: 0.6312 - val_loss: 0.7763 - val_acc: 0.5882\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 0s - loss: 0.7960 - acc: 0.6312 - val_loss: 0.7725 - val_acc: 0.7059\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 0s - loss: 0.8148 - acc: 0.5875 - val_loss: 0.7686 - val_acc: 0.7059\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 0s - loss: 0.8594 - acc: 0.5687 - val_loss: 0.7699 - val_acc: 0.7059\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 0s - loss: 0.8850 - acc: 0.5312 - val_loss: 0.7702 - val_acc: 0.7059\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 0s - loss: 0.8528 - acc: 0.5938 - val_loss: 0.7678 - val_acc: 0.7059\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 0s - loss: 0.8489 - acc: 0.6125 - val_loss: 0.7666 - val_acc: 0.7059\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 0s - loss: 0.8922 - acc: 0.5687 - val_loss: 0.7613 - val_acc: 0.7059\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 0s - loss: 0.7766 - acc: 0.6625 - val_loss: 0.7588 - val_acc: 0.7059\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 0s - loss: 0.7951 - acc: 0.6437 - val_loss: 0.7529 - val_acc: 0.7059\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 0s - loss: 0.8192 - acc: 0.6375 - val_loss: 0.7471 - val_acc: 0.7059\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 0s - loss: 0.7579 - acc: 0.6688 - val_loss: 0.7435 - val_acc: 0.7059\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 0s - loss: 0.7735 - acc: 0.6375 - val_loss: 0.7398 - val_acc: 0.7059\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 0s - loss: 0.7894 - acc: 0.6375 - val_loss: 0.7331 - val_acc: 0.7059\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 0s - loss: 0.7401 - acc: 0.6250 - val_loss: 0.7285 - val_acc: 0.7059\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 0s - loss: 0.7247 - acc: 0.6500 - val_loss: 0.7237 - val_acc: 0.7059\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 0s - loss: 0.7324 - acc: 0.6437 - val_loss: 0.7196 - val_acc: 0.7059\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 0s - loss: 0.7599 - acc: 0.6500 - val_loss: 0.7126 - val_acc: 0.7059\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 0s - loss: 0.7443 - acc: 0.6813 - val_loss: 0.7079 - val_acc: 0.7059\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 0s - loss: 0.7239 - acc: 0.6500 - val_loss: 0.7044 - val_acc: 0.7059\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 0s - loss: 0.7154 - acc: 0.6562 - val_loss: 0.6995 - val_acc: 0.7647\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 0s - loss: 0.7564 - acc: 0.6562 - val_loss: 0.6935 - val_acc: 0.7647\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 0s - loss: 0.7249 - acc: 0.6750 - val_loss: 0.6836 - val_acc: 0.7647\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 0s - loss: 0.6733 - acc: 0.7188 - val_loss: 0.6768 - val_acc: 0.7647\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 0s - loss: 0.6524 - acc: 0.7375 - val_loss: 0.6718 - val_acc: 0.7647\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 0s - loss: 0.7862 - acc: 0.6437 - val_loss: 0.6684 - val_acc: 0.7647\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 0s - loss: 0.6820 - acc: 0.6875 - val_loss: 0.6643 - val_acc: 0.7647\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 0s - loss: 0.6976 - acc: 0.6750 - val_loss: 0.6608 - val_acc: 0.7647\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 0s - loss: 0.7086 - acc: 0.7250 - val_loss: 0.6556 - val_acc: 0.7647\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 0s - loss: 0.7085 - acc: 0.6500 - val_loss: 0.6512 - val_acc: 0.8235\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 0s - loss: 0.7145 - acc: 0.6937 - val_loss: 0.6474 - val_acc: 0.8235\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 0s - loss: 0.7234 - acc: 0.6625 - val_loss: 0.6460 - val_acc: 0.8235\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 0s - loss: 0.6405 - acc: 0.7250 - val_loss: 0.6478 - val_acc: 0.7647\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 0s - loss: 0.6858 - acc: 0.6625 - val_loss: 0.6440 - val_acc: 0.7647\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 0s - loss: 0.8380 - acc: 0.5938 - val_loss: 0.6415 - val_acc: 0.7647\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 0s - loss: 0.7070 - acc: 0.7062 - val_loss: 0.6393 - val_acc: 0.7647\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 0s - loss: 0.7494 - acc: 0.6875 - val_loss: 0.6383 - val_acc: 0.7647\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 0s - loss: 0.6431 - acc: 0.7375 - val_loss: 0.6370 - val_acc: 0.7647\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 0s - loss: 0.6799 - acc: 0.7125 - val_loss: 0.6353 - val_acc: 0.7647\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 0s - loss: 0.6633 - acc: 0.6937 - val_loss: 0.6317 - val_acc: 0.7647\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 0s - loss: 0.6529 - acc: 0.7000 - val_loss: 0.6259 - val_acc: 0.7059\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 0s - loss: 0.6805 - acc: 0.7125 - val_loss: 0.6205 - val_acc: 0.7059\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 0s - loss: 0.6450 - acc: 0.7250 - val_loss: 0.6157 - val_acc: 0.7059\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 0s - loss: 0.6623 - acc: 0.6813 - val_loss: 0.6132 - val_acc: 0.7059\n",
      "Train on 160 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 1s - loss: 1.5138 - acc: 0.3687 - val_loss: 1.1286 - val_acc: 0.2941\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 0s - loss: 1.5302 - acc: 0.3375 - val_loss: 1.1193 - val_acc: 0.3529\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 0s - loss: 1.5354 - acc: 0.3375 - val_loss: 1.1105 - val_acc: 0.4118\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 0s - loss: 1.4081 - acc: 0.3875 - val_loss: 1.1073 - val_acc: 0.3529\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 0s - loss: 1.5464 - acc: 0.3438 - val_loss: 1.1057 - val_acc: 0.3529\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 0s - loss: 1.4014 - acc: 0.3250 - val_loss: 1.1022 - val_acc: 0.4118\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 0s - loss: 1.3708 - acc: 0.3813 - val_loss: 1.1008 - val_acc: 0.4118\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 0s - loss: 1.3248 - acc: 0.3188 - val_loss: 1.0954 - val_acc: 0.3529\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s - loss: 1.4363 - acc: 0.3375 - val_loss: 1.0915 - val_acc: 0.3529\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 0s - loss: 1.3675 - acc: 0.4312 - val_loss: 1.0875 - val_acc: 0.3529\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 0s - loss: 1.3348 - acc: 0.3687 - val_loss: 1.0803 - val_acc: 0.3529\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 0s - loss: 1.2848 - acc: 0.3813 - val_loss: 1.0737 - val_acc: 0.3529\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 0s - loss: 1.1976 - acc: 0.3687 - val_loss: 1.0668 - val_acc: 0.3529\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 0s - loss: 1.2987 - acc: 0.3563 - val_loss: 1.0602 - val_acc: 0.3529\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 0s - loss: 1.3318 - acc: 0.4000 - val_loss: 1.0546 - val_acc: 0.3529\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 0s - loss: 1.2692 - acc: 0.4000 - val_loss: 1.0502 - val_acc: 0.3529\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 0s - loss: 1.2619 - acc: 0.4500 - val_loss: 1.0475 - val_acc: 0.4118\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 0s - loss: 1.2735 - acc: 0.3750 - val_loss: 1.0456 - val_acc: 0.4118\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 0s - loss: 1.1958 - acc: 0.4625 - val_loss: 1.0377 - val_acc: 0.4706\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 0s - loss: 1.1978 - acc: 0.3625 - val_loss: 1.0337 - val_acc: 0.4706\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 0s - loss: 1.2194 - acc: 0.4312 - val_loss: 1.0273 - val_acc: 0.4706\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 0s - loss: 1.2111 - acc: 0.4562 - val_loss: 1.0196 - val_acc: 0.4706\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 0s - loss: 1.1366 - acc: 0.4312 - val_loss: 1.0147 - val_acc: 0.4706\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 0s - loss: 1.0809 - acc: 0.4750 - val_loss: 1.0091 - val_acc: 0.4706\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 0s - loss: 1.0904 - acc: 0.4688 - val_loss: 1.0038 - val_acc: 0.4706\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 0s - loss: 1.0896 - acc: 0.4625 - val_loss: 0.9988 - val_acc: 0.4706\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 0s - loss: 1.0697 - acc: 0.4625 - val_loss: 0.9905 - val_acc: 0.4706\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 0s - loss: 1.1416 - acc: 0.4062 - val_loss: 0.9832 - val_acc: 0.4706\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 0s - loss: 1.1636 - acc: 0.4375 - val_loss: 0.9755 - val_acc: 0.4706\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 0s - loss: 0.9433 - acc: 0.5812 - val_loss: 0.9724 - val_acc: 0.4706\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 0s - loss: 1.0895 - acc: 0.4688 - val_loss: 0.9706 - val_acc: 0.4118\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 0s - loss: 1.0127 - acc: 0.5375 - val_loss: 0.9685 - val_acc: 0.4118\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 0s - loss: 1.1069 - acc: 0.4500 - val_loss: 0.9666 - val_acc: 0.4706\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 0s - loss: 1.0791 - acc: 0.4937 - val_loss: 0.9653 - val_acc: 0.4118\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 0s - loss: 1.0816 - acc: 0.4438 - val_loss: 0.9646 - val_acc: 0.3529\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 0s - loss: 1.1029 - acc: 0.4688 - val_loss: 0.9656 - val_acc: 0.2941\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 0s - loss: 1.0208 - acc: 0.5187 - val_loss: 0.9628 - val_acc: 0.3529\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 0s - loss: 1.0031 - acc: 0.5000 - val_loss: 0.9614 - val_acc: 0.3529\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 0s - loss: 1.0684 - acc: 0.4500 - val_loss: 0.9607 - val_acc: 0.3529\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 0s - loss: 1.0493 - acc: 0.4562 - val_loss: 0.9605 - val_acc: 0.3529\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 0s - loss: 0.9749 - acc: 0.4937 - val_loss: 0.9605 - val_acc: 0.4118\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 0s - loss: 0.9564 - acc: 0.5250 - val_loss: 0.9612 - val_acc: 0.4118\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 0s - loss: 0.9814 - acc: 0.5312 - val_loss: 0.9619 - val_acc: 0.4118\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 0s - loss: 0.9949 - acc: 0.5000 - val_loss: 0.9619 - val_acc: 0.4118\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "k = 0\n",
    "test_score = []\n",
    "use_dnn = True\n",
    "for train_index, valid_index in kfold.split(x_train):\n",
    "    k += 1\n",
    "    X, X_V = x_train[train_index], x_train[valid_index]\n",
    "    Y, Y_V = y_train[train_index], y_train[valid_index]\n",
    "    \n",
    "    if use_dnn:\n",
    "        # DNN\n",
    "        Y, Y_V = np_utils.to_categorical(Y), np_utils.to_categorical(Y_V)\n",
    "        dnn = [32, 32, 32]\n",
    "        model = create_model(dnn)\n",
    "        callbacks = []\n",
    "        callbacks.append(EarlyStopping(monitor='val_loss', patience=3))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        model.fit(X, Y, batch_size=32, validation_data=(X_V, Y_V), \n",
    "                  epochs=100, callbacks=callbacks)\n",
    "        test_score.append(model.predict(x_test))\n",
    "    else:\n",
    "        # RF & GradientBoosting\n",
    "#         clf = GradientBoostingClassifier(n_estimators=40, min_samples_split=40, min_samples_leaf=3,\n",
    "#                                  max_leaf_nodes=15, max_depth=5, random_state=15)\n",
    "#         clf.fit(X, Y)\n",
    "#         test_score.append(clf.predict_proba(x_test))\n",
    "#         print('kfold ' + str(k) +  ' acc: '+ str(clf.score(X_V, Y_V)))\n",
    "        # Logistic Regression\n",
    "        lr = LogisticRegression(penalty='l2',C = 0.001,random_state = 0)\n",
    "        lr.fit(X, Y)\n",
    "        test_score.append(lr.predict_proba(x_test))\n",
    "        print('kfold ' + str(k) +  ' acc: '+ str(lr.score(X_V, Y_V)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.55\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "final_scores = np.zeros((len(x_test), 3))\n",
    "for i in range(k):\n",
    "    final_scores += test_score[i]\n",
    "test_pred = [np.argmax(x) for x in final_scores]\n",
    "test_acc = [1 if y_test[i] == test_pred[i] else 0 for i in range(len(y_test))]\n",
    "test_acc = np.sum(test_acc) / len(y_test)\n",
    "print('test_acc: ' + str(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
