{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def read_data(adjusted):\n",
    "#     if adjusted:\n",
    "#         data_file = pd.read_csv('MOVIES_ADJUSTED.csv', encoding='cp950')\n",
    "#         return data_file\n",
    "#     else:\n",
    "#         data_file = pd.read_csv('MOVIES_WITHOUT_ADJUSTED.csv', encoding='cp950')\n",
    "#         return data_file\n",
    "def preprocessing(data_file):\n",
    "    country = []\n",
    "    genre = []\n",
    "    date = []\n",
    "    for i in range(data_length):\n",
    "        t_country = str(data_file['COUNTRY'][i]).split(',')\n",
    "        t_genre = str(data_file['IMDB_GENRE'][i]).split(',')\n",
    "        t_date = str(data_file['DATE_TW'][i]).split('/')\n",
    "        t_date = [ int(d) for d in t_date]\n",
    "        country.append(t_country)\n",
    "        genre.append(t_genre)\n",
    "        date.append(t_date)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    country = mlb.fit_transform(country)\n",
    "    genre = mlb.fit_transform(genre)\n",
    "    date = np.array(date)\n",
    "    runtime = np.array(data_file['IMDB_RUNTIME']).reshape(data_length, 1)\n",
    "    dir_detail = np.array(data_file[['DIRECTOR_WINS', 'DIRECTOR_NOMINATIONS', \n",
    "                                     'DIRECTOR_RATINGS']])\n",
    "    star_detail = np.array(data_file[['STAR_1_WINS', 'STAR_1_NOMINATIONS', \n",
    "                                      'STAR_1_RATINGS', 'STAR_2_WINS', \n",
    "                                      'STAR_2_NOMINATIONS', 'STAR_2_RATINGS', \n",
    "                                      'STAR_3_WINS', 'STAR_3_NOMINATIONS', \n",
    "                                      'STAR_3_RATINGS']])\n",
    "    yahoo = np.array(data_file[['YAHOO_EVALUATION', 'YAHOO_VOTER']])\n",
    "    PTT = np.array(data_file[['PTT_ARTICLE', 'PTT_PUSH', 'PTT_ARROW', \n",
    "                              'PTT_PULL', 'PTT_REPLY']])\n",
    "    youtube = np.array(data_file[['YOUTUBE_VIEW', 'YOUTUBE_LIKE', 'YOUTUBE_DISLIKE']])\n",
    "    x_train = np.concatenate((country, genre, runtime, dir_detail, star_detail, \n",
    "                          yahoo, PTT, youtube), axis=-1)\n",
    "    rating = np.array(data_file['IMDB_RATING']).reshape(data_length, 1)\n",
    "    return x_train, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read training data\n",
    "x_train, y_train = np.load('x_train.npy'), np.load('y_train.npy')\n",
    "n_features = x_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "mean = np.mean(x_train, axis=0)\n",
    "sigma = np.std(x_train, axis=0)\n",
    "x_train = (x_train-mean)/(sigma + 1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read testing data\n",
    "x_test, y_test = np.load('x_test.npy'), np.load('y_test.npy')\n",
    "x_test = (x_test-mean)/(sigma + 1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    K.clip(y_pred, 1.0, 10.0)\n",
    "    return K.sqrt(K.mean(K.pow(y_true - y_pred, 2)))\n",
    "def create_model(dnn):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(n_features,), activation='tanh'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.3))\n",
    "    for units in dnn:\n",
    "        model.add(Dense(units, activation='tanh'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='tanh'))\n",
    "    model.add(Lambda(lambda x: x + K.constant(6.5558, dtype=K.floatx())))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 2s - loss: 1.3382 - rmse: 1.0980 - val_loss: 0.7027 - val_rmse: 0.8018\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.1135 - rmse: 1.0007 - val_loss: 0.4994 - val_rmse: 0.6987\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.0152 - rmse: 0.9702 - val_loss: 0.4859 - val_rmse: 0.6916\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 0.8217 - rmse: 0.8636 - val_loss: 0.4798 - val_rmse: 0.6848\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 0.7069 - rmse: 0.7906 - val_loss: 0.5181 - val_rmse: 0.7087\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 0.7520 - rmse: 0.8239 - val_loss: 0.5114 - val_rmse: 0.7043\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 0.7074 - rmse: 0.7930 - val_loss: 0.5186 - val_rmse: 0.7087\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 0.8750 - rmse: 0.8985 - val_loss: 0.5280 - val_rmse: 0.7129\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s - loss: 0.6499 - rmse: 0.7739 - val_loss: 0.5433 - val_rmse: 0.7189\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s - loss: 0.6463 - rmse: 0.7481 - val_loss: 0.5554 - val_rmse: 0.7233\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 2s - loss: 1.4008 - rmse: 1.1269 - val_loss: 0.8399 - val_rmse: 0.8450\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.0796 - rmse: 0.9947 - val_loss: 0.7446 - val_rmse: 0.8050\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.0745 - rmse: 0.9866 - val_loss: 0.7279 - val_rmse: 0.8119\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 0.9568 - rmse: 0.9470 - val_loss: 0.7941 - val_rmse: 0.8653\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 0.9990 - rmse: 0.9536 - val_loss: 0.6766 - val_rmse: 0.8051\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 1.0201 - rmse: 0.9762 - val_loss: 0.6188 - val_rmse: 0.7674\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 0.8768 - rmse: 0.8815 - val_loss: 0.5345 - val_rmse: 0.7166\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 0.7954 - rmse: 0.8574 - val_loss: 0.5039 - val_rmse: 0.6880\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s - loss: 0.8466 - rmse: 0.8737 - val_loss: 0.4573 - val_rmse: 0.6587\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s - loss: 0.8012 - rmse: 0.8361 - val_loss: 0.4119 - val_rmse: 0.6331\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s - loss: 0.7278 - rmse: 0.7939 - val_loss: 0.3999 - val_rmse: 0.6261\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s - loss: 0.7531 - rmse: 0.8193 - val_loss: 0.4396 - val_rmse: 0.6543\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s - loss: 0.5544 - rmse: 0.6830 - val_loss: 0.4549 - val_rmse: 0.6663\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s - loss: 0.7049 - rmse: 0.8119 - val_loss: 0.4305 - val_rmse: 0.6480\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 0s - loss: 0.6474 - rmse: 0.7662 - val_loss: 0.4225 - val_rmse: 0.6445\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 0s - loss: 0.6921 - rmse: 0.7956 - val_loss: 0.4166 - val_rmse: 0.6397\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 0s - loss: 0.6668 - rmse: 0.7690 - val_loss: 0.4539 - val_rmse: 0.6617\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 2s - loss: 1.0422 - rmse: 0.9475 - val_loss: 0.5166 - val_rmse: 0.7175\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.0221 - rmse: 0.9745 - val_loss: 0.4969 - val_rmse: 0.7019\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 0.8953 - rmse: 0.9074 - val_loss: 0.5053 - val_rmse: 0.7063\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 0.8951 - rmse: 0.9105 - val_loss: 0.4256 - val_rmse: 0.6468\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 0.9578 - rmse: 0.9397 - val_loss: 0.4295 - val_rmse: 0.6460\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 0.9038 - rmse: 0.9089 - val_loss: 0.3446 - val_rmse: 0.5769\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 0.7981 - rmse: 0.8505 - val_loss: 0.3330 - val_rmse: 0.5629\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 0.7160 - rmse: 0.7970 - val_loss: 0.4113 - val_rmse: 0.6156\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s - loss: 0.8543 - rmse: 0.8678 - val_loss: 0.3779 - val_rmse: 0.5964\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s - loss: 0.8352 - rmse: 0.8573 - val_loss: 0.3635 - val_rmse: 0.5855\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s - loss: 0.8141 - rmse: 0.8353 - val_loss: 0.3872 - val_rmse: 0.6020\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s - loss: 0.6829 - rmse: 0.7692 - val_loss: 0.3953 - val_rmse: 0.6096\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s - loss: 0.7080 - rmse: 0.7978 - val_loss: 0.4162 - val_rmse: 0.6253\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 2s - loss: 1.1328 - rmse: 1.0182 - val_loss: 0.3105 - val_rmse: 0.5309\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.0377 - rmse: 0.9309 - val_loss: 0.4151 - val_rmse: 0.6239\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.0780 - rmse: 0.9628 - val_loss: 0.5040 - val_rmse: 0.6966\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 0.8212 - rmse: 0.8503 - val_loss: 0.5416 - val_rmse: 0.7251\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 0.9172 - rmse: 0.8863 - val_loss: 0.6511 - val_rmse: 0.7892\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 0.7517 - rmse: 0.8262 - val_loss: 0.6911 - val_rmse: 0.8157\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 0.7970 - rmse: 0.8195 - val_loss: 0.6514 - val_rmse: 0.7926\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 2s - loss: 1.4483 - rmse: 1.1349 - val_loss: 0.5806 - val_rmse: 0.7501\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.1655 - rmse: 0.9987 - val_loss: 0.5508 - val_rmse: 0.7310\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.0202 - rmse: 0.9604 - val_loss: 0.5253 - val_rmse: 0.7083\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 0.9910 - rmse: 0.9444 - val_loss: 0.5577 - val_rmse: 0.7241\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 0.9423 - rmse: 0.9132 - val_loss: 0.5427 - val_rmse: 0.7174\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 0.8662 - rmse: 0.8942 - val_loss: 0.5693 - val_rmse: 0.7351\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 0.8657 - rmse: 0.8777 - val_loss: 0.4773 - val_rmse: 0.6706\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 0.9738 - rmse: 0.9209 - val_loss: 0.4231 - val_rmse: 0.6394\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s - loss: 0.9645 - rmse: 0.9413 - val_loss: 0.4574 - val_rmse: 0.6675\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s - loss: 0.7588 - rmse: 0.8176 - val_loss: 0.4946 - val_rmse: 0.6878\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s - loss: 0.8077 - rmse: 0.8491 - val_loss: 0.5210 - val_rmse: 0.7074\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s - loss: 0.7655 - rmse: 0.8150 - val_loss: 0.3824 - val_rmse: 0.6026\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s - loss: 0.7092 - rmse: 0.7900 - val_loss: 0.3666 - val_rmse: 0.5888\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s - loss: 0.6519 - rmse: 0.7641 - val_loss: 0.3503 - val_rmse: 0.5719\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 0s - loss: 0.7323 - rmse: 0.8106 - val_loss: 0.3244 - val_rmse: 0.5397\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 0s - loss: 0.7141 - rmse: 0.7851 - val_loss: 0.3091 - val_rmse: 0.5245\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159/159 [==============================] - 0s - loss: 0.8135 - rmse: 0.8448 - val_loss: 0.2803 - val_rmse: 0.4872\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 0s - loss: 0.7623 - rmse: 0.8373 - val_loss: 0.2814 - val_rmse: 0.4885\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 0s - loss: 0.7060 - rmse: 0.7923 - val_loss: 0.2498 - val_rmse: 0.4575\n",
      "Epoch 20/100\n",
      "159/159 [==============================] - 0s - loss: 0.6673 - rmse: 0.7783 - val_loss: 0.2418 - val_rmse: 0.4562\n",
      "Epoch 21/100\n",
      "159/159 [==============================] - 0s - loss: 0.7310 - rmse: 0.7858 - val_loss: 0.2466 - val_rmse: 0.4571\n",
      "Epoch 22/100\n",
      "159/159 [==============================] - 0s - loss: 0.6987 - rmse: 0.7934 - val_loss: 0.2570 - val_rmse: 0.4652\n",
      "Epoch 23/100\n",
      "159/159 [==============================] - 0s - loss: 0.6485 - rmse: 0.7636 - val_loss: 0.2684 - val_rmse: 0.4811\n",
      "Epoch 24/100\n",
      "159/159 [==============================] - 0s - loss: 0.7019 - rmse: 0.7960 - val_loss: 0.2551 - val_rmse: 0.4651\n",
      "Epoch 25/100\n",
      "159/159 [==============================] - 0s - loss: 0.7131 - rmse: 0.8136 - val_loss: 0.2411 - val_rmse: 0.4460\n",
      "Epoch 26/100\n",
      "159/159 [==============================] - 0s - loss: 0.7437 - rmse: 0.8011 - val_loss: 0.2400 - val_rmse: 0.4455\n",
      "Epoch 27/100\n",
      "159/159 [==============================] - 0s - loss: 0.5860 - rmse: 0.7293 - val_loss: 0.2364 - val_rmse: 0.4417\n",
      "Epoch 28/100\n",
      "159/159 [==============================] - 0s - loss: 0.6087 - rmse: 0.7396 - val_loss: 0.2326 - val_rmse: 0.4415\n",
      "Epoch 29/100\n",
      "159/159 [==============================] - 0s - loss: 0.6022 - rmse: 0.7101 - val_loss: 0.2372 - val_rmse: 0.4526\n",
      "Epoch 30/100\n",
      "159/159 [==============================] - 0s - loss: 0.6412 - rmse: 0.7487 - val_loss: 0.2552 - val_rmse: 0.4783\n",
      "Epoch 31/100\n",
      "159/159 [==============================] - 0s - loss: 0.6814 - rmse: 0.7749 - val_loss: 0.2562 - val_rmse: 0.4810\n",
      "Epoch 32/100\n",
      "159/159 [==============================] - 0s - loss: 0.5718 - rmse: 0.7053 - val_loss: 0.2628 - val_rmse: 0.4902\n",
      "Epoch 33/100\n",
      "159/159 [==============================] - 0s - loss: 0.6599 - rmse: 0.7614 - val_loss: 0.2546 - val_rmse: 0.4841\n",
      "Epoch 34/100\n",
      "159/159 [==============================] - 0s - loss: 0.6044 - rmse: 0.7381 - val_loss: 0.2281 - val_rmse: 0.4526\n",
      "Epoch 35/100\n",
      "159/159 [==============================] - 0s - loss: 0.5403 - rmse: 0.6944 - val_loss: 0.2599 - val_rmse: 0.4940\n",
      "Epoch 36/100\n",
      "159/159 [==============================] - 0s - loss: 0.6536 - rmse: 0.7575 - val_loss: 0.2297 - val_rmse: 0.4564\n",
      "Epoch 37/100\n",
      "159/159 [==============================] - 0s - loss: 0.6151 - rmse: 0.7316 - val_loss: 0.2325 - val_rmse: 0.4663\n",
      "Epoch 38/100\n",
      "159/159 [==============================] - 0s - loss: 0.6019 - rmse: 0.7357 - val_loss: 0.2178 - val_rmse: 0.4511\n",
      "Epoch 39/100\n",
      "159/159 [==============================] - 0s - loss: 0.5895 - rmse: 0.7247 - val_loss: 0.2371 - val_rmse: 0.4734\n",
      "Epoch 40/100\n",
      "159/159 [==============================] - 0s - loss: 0.5189 - rmse: 0.6822 - val_loss: 0.2186 - val_rmse: 0.4516\n",
      "Epoch 41/100\n",
      "159/159 [==============================] - 0s - loss: 0.4804 - rmse: 0.6484 - val_loss: 0.1990 - val_rmse: 0.4285\n",
      "Epoch 42/100\n",
      "159/159 [==============================] - 0s - loss: 0.6236 - rmse: 0.7538 - val_loss: 0.2082 - val_rmse: 0.4443\n",
      "Epoch 43/100\n",
      "159/159 [==============================] - 0s - loss: 0.6190 - rmse: 0.7383 - val_loss: 0.2490 - val_rmse: 0.4921\n",
      "Epoch 44/100\n",
      "159/159 [==============================] - 0s - loss: 0.5875 - rmse: 0.7423 - val_loss: 0.2510 - val_rmse: 0.4909\n",
      "Epoch 45/100\n",
      "159/159 [==============================] - 0s - loss: 0.5494 - rmse: 0.6949 - val_loss: 0.1949 - val_rmse: 0.4157\n",
      "Epoch 46/100\n",
      "159/159 [==============================] - 0s - loss: 0.5837 - rmse: 0.7128 - val_loss: 0.2370 - val_rmse: 0.4687\n",
      "Epoch 47/100\n",
      "159/159 [==============================] - 0s - loss: 0.6002 - rmse: 0.7339 - val_loss: 0.2325 - val_rmse: 0.4632\n",
      "Epoch 48/100\n",
      "159/159 [==============================] - 0s - loss: 0.4792 - rmse: 0.6293 - val_loss: 0.2394 - val_rmse: 0.4669\n",
      "Epoch 49/100\n",
      "159/159 [==============================] - 0s - loss: 0.5704 - rmse: 0.7115 - val_loss: 0.2251 - val_rmse: 0.4422\n",
      "Epoch 50/100\n",
      "159/159 [==============================] - 0s - loss: 0.5269 - rmse: 0.6661 - val_loss: 0.2302 - val_rmse: 0.4449\n",
      "Epoch 51/100\n",
      "159/159 [==============================] - 0s - loss: 0.5219 - rmse: 0.6836 - val_loss: 0.2277 - val_rmse: 0.4449\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 2s - loss: 1.5012 - rmse: 1.1936 - val_loss: 0.6066 - val_rmse: 0.7440\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 1.3131 - rmse: 1.0877 - val_loss: 0.5778 - val_rmse: 0.7348\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 1.1752 - rmse: 1.0385 - val_loss: 0.6916 - val_rmse: 0.8152\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 1.1196 - rmse: 1.0059 - val_loss: 0.8000 - val_rmse: 0.8728\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 1.0859 - rmse: 0.9995 - val_loss: 0.8430 - val_rmse: 0.9014\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 0.9198 - rmse: 0.9254 - val_loss: 0.8424 - val_rmse: 0.8930\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 0.9039 - rmse: 0.8814 - val_loss: 0.8808 - val_rmse: 0.9193\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 0.9452 - rmse: 0.9332 - val_loss: 0.9046 - val_rmse: 0.9352\n",
      "Train on 159 samples, validate on 18 samples\n",
      "Epoch 1/100\n",
      "159/159 [==============================] - 2s - loss: 0.9732 - rmse: 0.9597 - val_loss: 1.1049 - val_rmse: 0.9798\n",
      "Epoch 2/100\n",
      "159/159 [==============================] - 0s - loss: 0.8994 - rmse: 0.9037 - val_loss: 0.9940 - val_rmse: 0.9250\n",
      "Epoch 3/100\n",
      "159/159 [==============================] - 0s - loss: 0.9323 - rmse: 0.9066 - val_loss: 0.9796 - val_rmse: 0.9108\n",
      "Epoch 4/100\n",
      "159/159 [==============================] - 0s - loss: 0.7875 - rmse: 0.8451 - val_loss: 0.9621 - val_rmse: 0.8986\n",
      "Epoch 5/100\n",
      "159/159 [==============================] - 0s - loss: 0.7871 - rmse: 0.8339 - val_loss: 0.9598 - val_rmse: 0.8980\n",
      "Epoch 6/100\n",
      "159/159 [==============================] - 0s - loss: 0.8097 - rmse: 0.8310 - val_loss: 0.9370 - val_rmse: 0.8902\n",
      "Epoch 7/100\n",
      "159/159 [==============================] - 0s - loss: 0.9215 - rmse: 0.9150 - val_loss: 0.8975 - val_rmse: 0.8787\n",
      "Epoch 8/100\n",
      "159/159 [==============================] - 0s - loss: 0.7213 - rmse: 0.8020 - val_loss: 0.8760 - val_rmse: 0.8661\n",
      "Epoch 9/100\n",
      "159/159 [==============================] - 0s - loss: 0.7744 - rmse: 0.8477 - val_loss: 0.8583 - val_rmse: 0.8604\n",
      "Epoch 10/100\n",
      "159/159 [==============================] - 0s - loss: 0.7301 - rmse: 0.8210 - val_loss: 0.8556 - val_rmse: 0.8598\n",
      "Epoch 11/100\n",
      "159/159 [==============================] - 0s - loss: 0.6731 - rmse: 0.7866 - val_loss: 0.8323 - val_rmse: 0.8485\n",
      "Epoch 12/100\n",
      "159/159 [==============================] - 0s - loss: 0.7120 - rmse: 0.7977 - val_loss: 0.8366 - val_rmse: 0.8440\n",
      "Epoch 13/100\n",
      "159/159 [==============================] - 0s - loss: 0.7704 - rmse: 0.8383 - val_loss: 0.8300 - val_rmse: 0.8406\n",
      "Epoch 14/100\n",
      "159/159 [==============================] - 0s - loss: 0.6373 - rmse: 0.7565 - val_loss: 0.8534 - val_rmse: 0.8552\n",
      "Epoch 15/100\n",
      "159/159 [==============================] - 0s - loss: 0.7220 - rmse: 0.8009 - val_loss: 0.8588 - val_rmse: 0.8570\n",
      "Epoch 16/100\n",
      "159/159 [==============================] - 0s - loss: 0.6513 - rmse: 0.7644 - val_loss: 0.8499 - val_rmse: 0.8542\n",
      "Epoch 17/100\n",
      "159/159 [==============================] - 0s - loss: 0.6709 - rmse: 0.7821 - val_loss: 0.8497 - val_rmse: 0.8518\n",
      "Epoch 18/100\n",
      "159/159 [==============================] - 0s - loss: 0.7899 - rmse: 0.8467 - val_loss: 0.8714 - val_rmse: 0.8667\n",
      "Epoch 19/100\n",
      "159/159 [==============================] - 0s - loss: 0.6323 - rmse: 0.7616 - val_loss: 0.9271 - val_rmse: 0.8926\n",
      "Train on 160 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 3s - loss: 1.2149 - rmse: 1.0387 - val_loss: 0.7058 - val_rmse: 0.8072\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160/160 [==============================] - 0s - loss: 1.0863 - rmse: 0.9629 - val_loss: 0.6373 - val_rmse: 0.7620\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 0s - loss: 1.0834 - rmse: 0.9939 - val_loss: 0.6745 - val_rmse: 0.7698\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 0s - loss: 0.8900 - rmse: 0.8765 - val_loss: 0.7766 - val_rmse: 0.8186\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 0s - loss: 0.9687 - rmse: 0.9086 - val_loss: 0.7769 - val_rmse: 0.8046\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 0s - loss: 0.8483 - rmse: 0.8636 - val_loss: 0.6751 - val_rmse: 0.7554\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 0s - loss: 0.9114 - rmse: 0.8902 - val_loss: 0.7366 - val_rmse: 0.7993\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 0s - loss: 0.7917 - rmse: 0.8364 - val_loss: 0.7802 - val_rmse: 0.8162\n",
      "Train on 160 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 2s - loss: 1.3266 - rmse: 1.1038 - val_loss: 0.8000 - val_rmse: 0.8495\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 0s - loss: 1.1508 - rmse: 1.0085 - val_loss: 0.7685 - val_rmse: 0.8023\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 0s - loss: 1.1900 - rmse: 1.0268 - val_loss: 0.7152 - val_rmse: 0.7425\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 0s - loss: 0.9412 - rmse: 0.9270 - val_loss: 0.6117 - val_rmse: 0.7173\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 0s - loss: 0.9454 - rmse: 0.9076 - val_loss: 0.4974 - val_rmse: 0.6737\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 0s - loss: 0.7870 - rmse: 0.8440 - val_loss: 0.4871 - val_rmse: 0.6803\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 0s - loss: 0.8366 - rmse: 0.8581 - val_loss: 0.5210 - val_rmse: 0.7099\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 0s - loss: 0.8434 - rmse: 0.8655 - val_loss: 0.5289 - val_rmse: 0.7163\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 0s - loss: 0.8733 - rmse: 0.8991 - val_loss: 0.5556 - val_rmse: 0.7329\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 0s - loss: 0.7561 - rmse: 0.8279 - val_loss: 0.5479 - val_rmse: 0.7255\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 0s - loss: 0.6613 - rmse: 0.7744 - val_loss: 0.5471 - val_rmse: 0.7233\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 0s - loss: 0.6710 - rmse: 0.7757 - val_loss: 0.5382 - val_rmse: 0.7174\n",
      "Train on 160 samples, validate on 17 samples\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 2s - loss: 1.4733 - rmse: 1.1664 - val_loss: 1.2560 - val_rmse: 1.0564\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 0s - loss: 1.3288 - rmse: 1.0939 - val_loss: 1.1502 - val_rmse: 0.9984\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 0s - loss: 1.2300 - rmse: 1.0797 - val_loss: 1.1836 - val_rmse: 1.0073\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 0s - loss: 1.1258 - rmse: 1.0293 - val_loss: 1.1078 - val_rmse: 0.9686\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 0s - loss: 1.0870 - rmse: 1.0090 - val_loss: 0.9817 - val_rmse: 0.9053\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 0s - loss: 0.8728 - rmse: 0.8913 - val_loss: 0.9292 - val_rmse: 0.8657\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 0s - loss: 1.1154 - rmse: 1.0229 - val_loss: 0.8531 - val_rmse: 0.8261\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 0s - loss: 0.8745 - rmse: 0.9082 - val_loss: 0.8522 - val_rmse: 0.8317\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 0s - loss: 0.8995 - rmse: 0.9035 - val_loss: 0.8456 - val_rmse: 0.8236\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 0s - loss: 0.8495 - rmse: 0.8825 - val_loss: 0.8797 - val_rmse: 0.8476\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 0s - loss: 0.7728 - rmse: 0.8152 - val_loss: 0.8708 - val_rmse: 0.8477\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 0s - loss: 0.7509 - rmse: 0.8230 - val_loss: 0.8453 - val_rmse: 0.8378\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 0s - loss: 0.8296 - rmse: 0.8641 - val_loss: 0.8156 - val_rmse: 0.8249\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 0s - loss: 0.9034 - rmse: 0.9089 - val_loss: 0.8306 - val_rmse: 0.8415\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 0s - loss: 0.8415 - rmse: 0.8804 - val_loss: 0.8659 - val_rmse: 0.8664\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 0s - loss: 0.7753 - rmse: 0.8095 - val_loss: 0.8348 - val_rmse: 0.8501\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 0s - loss: 0.6462 - rmse: 0.7714 - val_loss: 0.8065 - val_rmse: 0.8283\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 0s - loss: 0.7390 - rmse: 0.8055 - val_loss: 0.8122 - val_rmse: 0.8301\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 0s - loss: 0.5952 - rmse: 0.7270 - val_loss: 0.8055 - val_rmse: 0.8265\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 0s - loss: 0.6702 - rmse: 0.7622 - val_loss: 0.7941 - val_rmse: 0.8225\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 0s - loss: 0.6301 - rmse: 0.7498 - val_loss: 0.7441 - val_rmse: 0.7935\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 0s - loss: 0.5697 - rmse: 0.7152 - val_loss: 0.7120 - val_rmse: 0.7707\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 0s - loss: 0.5366 - rmse: 0.7073 - val_loss: 0.7044 - val_rmse: 0.7670\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 0s - loss: 0.5751 - rmse: 0.7252 - val_loss: 0.6966 - val_rmse: 0.7609\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 0s - loss: 0.6434 - rmse: 0.7325 - val_loss: 0.6985 - val_rmse: 0.7639\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 0s - loss: 0.6811 - rmse: 0.7818 - val_loss: 0.7115 - val_rmse: 0.7734\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 0s - loss: 0.7204 - rmse: 0.7949 - val_loss: 0.7206 - val_rmse: 0.7817\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 0s - loss: 0.6909 - rmse: 0.7825 - val_loss: 0.7280 - val_rmse: 0.7927\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 0s - loss: 0.7169 - rmse: 0.8066 - val_loss: 0.7541 - val_rmse: 0.8159\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 0s - loss: 0.6599 - rmse: 0.7726 - val_loss: 0.7558 - val_rmse: 0.8081\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=5)\n",
    "k = 0\n",
    "test_score = []\n",
    "for train_index, valid_index in kfold.split(x_train):\n",
    "    k += 1\n",
    "    X, X_V = x_train[train_index], x_train[valid_index]\n",
    "    Y, Y_V = y_train[train_index], y_train[valid_index]\n",
    "    \n",
    "    # DNN\n",
    "    dnn = [32, 32]\n",
    "    model = create_model(dnn)\n",
    "    callbacks = []\n",
    "    callbacks.append(EarlyStopping(monitor='val_loss', patience=3))\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[rmse])\n",
    "    model.fit(X, Y, batch_size=32, validation_data=(X_V, Y_V), \n",
    "              epochs=100, callbacks=callbacks)\n",
    "    test_score.append(model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.757745652199\n"
     ]
    }
   ],
   "source": [
    "# test accuracy\n",
    "final_scores = np.zeros((len(x_test), 1))\n",
    "for i in range(k):\n",
    "    final_scores += test_score[i]\n",
    "test_pred = final_scores / k\n",
    "test_loss = [ np.abs(y_test[i] - test_pred[i])  for i in range(len(y_test))]\n",
    "test_loss = np.sum(test_loss) / len(y_test)\n",
    "print('test_acc: ' + str(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
