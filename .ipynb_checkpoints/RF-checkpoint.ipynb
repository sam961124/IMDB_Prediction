{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Activation, BatchNormalization, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = pd.read_csv('MOVIES_WITHOUT_PTT_TIME_ASC.csv', encoding='cp950')\n",
    "test_file = pd.read_csv('Testing.csv')\n",
    "data_length = len(data_file)\n",
    "test_length = len(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = []\n",
    "genre = []\n",
    "date = []\n",
    "test_country = []\n",
    "test_genre = []\n",
    "test_date = []\n",
    "for i in range(data_length):\n",
    "    t_country = str(data_file['COUNTRY'][i]).split(',')\n",
    "    t_genre = str(data_file['IMDB_GENRE'][i]).split(',')\n",
    "    t_date = str(data_file['DATE_TW'][i]).split('/')\n",
    "    t_date = [ int(d) for d in t_date]\n",
    "    country.append(t_country)\n",
    "    genre.append(t_genre)\n",
    "    date.append(t_date)\n",
    "for i in range(test_length):\n",
    "    t_country = str(test_file['COUNTRY'][i]).split(',')\n",
    "    t_genre = str(test_file['IMDB_GENRE'][i]).split(',')\n",
    "    t_date = str(test_file['DATE_TW'][i]).split('/')\n",
    "    t_date = [ int(d) for d in t_date]\n",
    "    test_country.append(t_country)\n",
    "    test_genre.append(t_genre)\n",
    "    test_date.append(t_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "all_country = mlb.fit_transform(country + test_country)\n",
    "all_genre = mlb.fit_transform(genre + test_genre)\n",
    "country = all_country[:-20]\n",
    "test_country = all_country[-20:]\n",
    "genre = all_genre[:-20]\n",
    "test_genre = all_genre[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date = np.array(date)\n",
    "runtime = np.array(data_file['IMDB_RUNTIME']).reshape(data_length, 1)\n",
    "dir_detail = np.array(data_file[['DIRECTOR_WINS', 'DIRECTOR_NOMINATIONS', \n",
    "                                 'DIRECTOR_RATINGS']])\n",
    "star_detail = np.array(data_file[['STAR_1_WINS', 'STAR_1_NOMINATIONS', \n",
    "                                  'STAR_1_RATINGS', 'STAR_2_WINS', \n",
    "                                  'STAR_2_NOMINATIONS', 'STAR_2_RATINGS', \n",
    "                                  'STAR_3_WINS', 'STAR_3_NOMINATIONS', \n",
    "                                  'STAR_3_RATINGS']])\n",
    "yahoo = np.array(data_file[['YAHOO_EVALUATION', 'YAHOO_VOTER']])\n",
    "PTT = np.array(data_file[['PTT_ARTICLE', 'PTT_PUSH', 'PTT_ARROW', \n",
    "                          'PTT_PULL', 'PTT_REPLY']])\n",
    "youtube = np.array(data_file[['YOUTUBE_VIEW', 'YOUTUBE_LIKE', 'YOUTUBE_DISLIKE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_date = np.array(test_date)\n",
    "test_runtime = np.array(test_file['IMDB_RUNTIME']).reshape(test_length, 1)\n",
    "test_dir_detail = np.array(test_file[['DIRECTOR_WINS', 'DIRECTOR_NOMINATIONS', \n",
    "                                 'DIRECTOR_RATINGS']])\n",
    "test_star_detail = np.array(test_file[['STAR_1_WINS', 'STAR_1_NOMINATIONS', \n",
    "                                  'STAR_1_RATINGS', 'STAR_2_WINS', \n",
    "                                  'STAR_2_NOMINATIONS', 'STAR_2_RATINGS', \n",
    "                                  'STAR_3_WINS', 'STAR_3_NOMINATIONS', \n",
    "                                  'STAR_3_RATINGS']])\n",
    "test_yahoo = np.array(test_file[['YAHOO_EVALUATION', 'YAHOO_VOTER']])\n",
    "test_PTT = np.array(test_file[['PTT_ARTICLE', 'PTT_PUSH', 'PTT_ARROW', \n",
    "                          'PTT_PULL', 'PTT_REPLY']])\n",
    "test_youtube = np.array(test_file[['YOUTUBE_VIEW', 'YOUTUBE_LIKE', 'YOUTUBE_DISLIKE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((date, country, genre, runtime, dir_detail, star_detail,yahoo), axis=-1)\n",
    "y_train = np.array(data_file['IMDB_RATING']).reshape(data_length, 1)\n",
    "\n",
    "x_test = np.concatenate((test_date, test_country, test_genre, test_runtime, \n",
    "                         test_dir_detail, test_star_detail, test_yahoo), axis=-1)\n",
    "y_test = np.array(test_file['IMDB_RATING']).reshape(test_length, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(x_train, axis=0)\n",
    "sigma = np.std(x_train, axis=0)\n",
    "x_train = (x_train-mean)/(sigma + 1e-20)\n",
    "x_test = (x_test-mean)/(sigma + 1e-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_valid = x_train[-20:]\n",
    "y_valid = y_train[-20:]\n",
    "\n",
    "x_train = x_train[:-20]\n",
    "y_train = y_train[:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.737761709283\n",
      "train score: 0.476841499974\n",
      "valid score: 1.97780123855\n",
      "test score: 2.24780782836\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "y_pred = lr.predict(x_train).clip(1,10)\n",
    "y_pred_valid = lr.predict(x_valid).clip(1,10)\n",
    "y_pred_test = lr.predict(x_test).clip(1,10)\n",
    "print('R^2: ' + str(lr.score(x_train, y_train)))\n",
    "print('train score: ' + str(np.sqrt(mean_squared_error(y_train, y_pred))))\n",
    "print('valid score: ' + str(np.sqrt(mean_squared_error(y_valid, y_pred_valid))))\n",
    "print('test score: ' + str(np.sqrt(mean_squared_error(y_test, y_pred_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_regression_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(x_train.shape[1],), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.add(Lambda(lambda x: x + K.constant(6.5558, dtype=K.floatx())))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    K.clip(y_pred, 1.0, 10.0)\n",
    "    return K.sqrt(K.mean(K.pow(y_true - y_pred, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 177 samples, validate on 20 samples\n",
      "Epoch 1/100\n",
      "177/177 [==============================] - 3s - loss: 1.2134 - rmse: 1.2134 - val_loss: 0.9952 - val_rmse: 0.9952\n",
      "Epoch 2/100\n",
      "177/177 [==============================] - 0s - loss: 1.0428 - rmse: 1.0428 - val_loss: 1.0091 - val_rmse: 1.0091\n",
      "Epoch 3/100\n",
      "177/177 [==============================] - 0s - loss: 0.9157 - rmse: 0.9157 - val_loss: 1.0070 - val_rmse: 1.0070\n",
      "Epoch 4/100\n",
      "177/177 [==============================] - 0s - loss: 0.9302 - rmse: 0.9302 - val_loss: 0.9951 - val_rmse: 0.9951\n",
      "Epoch 5/100\n",
      "177/177 [==============================] - 0s - loss: 0.8774 - rmse: 0.8774 - val_loss: 0.9987 - val_rmse: 0.9987\n",
      "Epoch 6/100\n",
      "177/177 [==============================] - 0s - loss: 0.9240 - rmse: 0.9240 - val_loss: 0.9589 - val_rmse: 0.9589\n",
      "Epoch 7/100\n",
      "177/177 [==============================] - 0s - loss: 0.8788 - rmse: 0.8788 - val_loss: 0.9445 - val_rmse: 0.9445\n",
      "Epoch 8/100\n",
      "177/177 [==============================] - 0s - loss: 0.8845 - rmse: 0.8845 - val_loss: 0.9341 - val_rmse: 0.9341\n",
      "Epoch 9/100\n",
      "177/177 [==============================] - 0s - loss: 0.8581 - rmse: 0.8581 - val_loss: 0.9179 - val_rmse: 0.9179\n",
      "Epoch 10/100\n",
      "177/177 [==============================] - 0s - loss: 0.8987 - rmse: 0.8987 - val_loss: 0.9450 - val_rmse: 0.9450\n",
      "Epoch 11/100\n",
      "177/177 [==============================] - 0s - loss: 0.8624 - rmse: 0.8624 - val_loss: 0.9468 - val_rmse: 0.9468\n",
      "Epoch 12/100\n",
      "177/177 [==============================] - 0s - loss: 0.8478 - rmse: 0.8478 - val_loss: 0.9334 - val_rmse: 0.9334\n",
      "Epoch 13/100\n",
      "177/177 [==============================] - 0s - loss: 0.8846 - rmse: 0.8846 - val_loss: 0.9272 - val_rmse: 0.9272\n",
      "Epoch 14/100\n",
      "177/177 [==============================] - 0s - loss: 0.8331 - rmse: 0.8331 - val_loss: 0.9291 - val_rmse: 0.9291\n",
      "Epoch 15/100\n",
      "177/177 [==============================] - 0s - loss: 0.8314 - rmse: 0.8314 - val_loss: 0.9269 - val_rmse: 0.9269\n",
      "test score: 1.36348546976\n"
     ]
    }
   ],
   "source": [
    "r_model = create_regression_model()\n",
    "callbacks = []\n",
    "callbacks.append(ModelCheckpoint('model.h5',\n",
    "                                 monitor='val_loss', save_best_only=True, period=1))\n",
    "callbacks.append(EarlyStopping(monitor='val_loss', patience=5))\n",
    "r_model.compile(loss=rmse, optimizer='adam', metrics=[rmse])\n",
    "r_model.fit(x_train, y_train, batch_size=5, validation_data=(x_valid, y_valid), \n",
    "          epochs=100, callbacks=callbacks)\n",
    "\n",
    "r_model = load_model('model.h5', custom_objects={'rmse': rmse})\n",
    "y_pred_test = r_model.predict(x_test).clip(1,10)\n",
    "print('test score: ' + str(np.sqrt(mean_squared_error(y_test, y_pred_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_y_train = []\n",
    "for r in y_train:\n",
    "    temp = 0\n",
    "    if r >= 7:\n",
    "        temp = 0\n",
    "    elif r >= 6.2:\n",
    "        temp = 1\n",
    "    else:\n",
    "        temp = 2\n",
    "    c_y_train.append(temp)\n",
    "c_y_train = np.array(c_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_y_test = []\n",
    "for r in y_test:\n",
    "    temp = 0\n",
    "    if r >= 7:\n",
    "        temp = 0\n",
    "    elif r >= 6.2:\n",
    "        temp = 1\n",
    "    else:\n",
    "        temp = 2\n",
    "    c_y_test.append(temp)\n",
    "c_y_test = np.array(c_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_x_valid = x_train[-20:]\n",
    "c_y_valid = c_y_train[-20:]\n",
    "\n",
    "c_x_train = x_train[:-20]\n",
    "c_y_train = c_y_train[:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score: 0.920903954802\n",
      "valid score: 0.55\n",
      "test score: 0.5\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=200, min_samples_leaf=5, max_depth=5, random_state=0)\n",
    "clf.fit(c_x_train, c_y_train)\n",
    "print('train score: ' + str(clf.score(c_x_train, c_y_train)))\n",
    "print('valid score: ' + str(clf.score(c_x_valid, c_y_valid)))\n",
    "print('test score: ' + str(clf.score(x_test, c_y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
